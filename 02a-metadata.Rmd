# FAIR Data and the Added Value of Rich Metadata {#FAIR-data}

<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 50%" />
<col style="width: 25%" />
</colgroup>
<tbody>
<tr class="even">
<td style="text-align: center;  vertical-align: top;"><img src="plots/gems/Diamond_Polisher.jpg" /><a href="https://contributors.dataobservatory.eu/FAIR-data.html">Adding metadata exponentially increases the value of data</a></br>Did your region added a new town to its boundaries – how do you adjust old data? Can I practically combine satellite sensory data with my organization records? And do I have the right? Metadata logs the history of the data, gives instructions who to reuse it in indicators, sets the terms of use. We automate this boring and labor-intensive process applying the [FAIR](https://contributors.dataobservatory.eu/FAIR-data.html#FAIR) data concept.</br></td>
</tr>
</tbody>
</table>

The FAIR Data concept stands for **f**indable, **a**ccessibe, **i**nteroperable, and **r**eusable of digital assets.

The problem with [Open Data](#open-data) is that while it is legally accessible, and often cost-free, it in most cases not findable, and not even accessible directly. While the EU has policies since 2003 about making taxpayer funded data reusable, it did not make much technical steps to make this a reality.  Reusability of governmental data and scientific data is a right, but not a practical possiblity for most users.

Interoperability means that you can use governmental open data, scientific open data, your own system's data, your membership organizations shared resources, and data subscriptions together. A special case of lack of interoperability when you do not know if you are facing a legal risk from using a data resource.

In our experience, in most research-driven organizations, such as consultancies, law firms, university research groups, NGOs and public policy bodies, reusability is mainly limited by poor data documentation, and sometimes by the use of of obsolete proprietary file formats. Documentation in the short run is not always a necessity, and it belongs to the non-billable hours, or among the tasks that do not really count in a researchers' promotion. The poor documentation however makes it extremely demanding to re-use a data or document a few years from now. From 2021, if you apply for Horizon Europe funding, your research output must meet basic findability and reusability criteria. 

We believe that the most value in our research automation comes from the documentation automation, which adds automatically rich descriptive, administrative and processing metadata to your data assets. Our data comes with metadata that meets the requirements of two metadata standards, the more general [Dublin Core](#Dublin-Core) and the more specific, mandatory and recommended values of [DataCite](#DataCite) for datasets. We add rich processing metadata beyond these requirements. These are not only nice to have: from 2021, if you apply for Our solution can automate this process, and besides making you compliant, it adds a lot of value to your own data management.

We are making our API service FAIR by automatically adding to our data standardized metadata that fulfills the mandatory requirements of the Dublic Core metadata standards and at the same time the [mandatory requirements](https://support.datacite.org/docs/datacite-metadata-schema-v44-mandatory-properties), and most of the [recommended requirements](https://support.datacite.org/docs/datacite-metadata-schema-v44-recommended-and-optional-properties) of DataCite.

Furthermore, we apply the [tidy data](#tidy-data) concept to our main data assets. The tidy data principle applies a certain structure to datasets that facilitates immediate use and reuse. 

## FAIR {#FAIR}

In 2016, the **[FAIR Guiding Principles for scientific data management and stewardship](http://www.nature.com/articles/sdata201618)** were published in _Scientific Data_. The authors intended to provide guidelines to improve the **F**indability, **A**ccessibility, **I**nteroperability, and **R**euse of digital assets. The principles emphasize machine-actionability (i.e., the capacity of computational systems to find, access, interoperate, and reuse data with none or minimal human intervention) because humans increasingly rely on computational support to deal with data because of the increase in volume, complexity, and creation speed of data.

A practical “how to” guidance to go FAIR can be found in the **[Three-point FAIRification Framework](https://www.go-fair.org/how-to-go-fair/)**.

**<span style="text-decoration:underline;">F</span>indable**

The first step in (re)using data is to find them. Metadata and data should be easy to find for both humans and computers. Machine-readable metadata are essential for automatic discovery of datasets and services, so this is an essential component of the **[FAIRification process](https://www.go-fair.org/fair-principles/fairification-process/)**.

**[F1. (Meta)data are assigned a globally unique and persistent identifier](https://www.go-fair.org/fair-principles/fair-data-principles-explained/f1-meta-data-assigned-globally-unique-persistent-identifiers/)**

**[F2. Data are described with rich metadata (defined by R1 below)](https://www.go-fair.org/fair-principles/fair-data-principles-explained/f2-data-described-rich-metadata/)**

**[F3. Metadata clearly and explicitly include the identifier of the data they describe](https://www.go-fair.org/fair-principles/f3-metadata-clearly-explicitly-include-identifier-data-describe/)**

**[F4. (Meta)data are registered or indexed in a searchable resource](https://www.go-fair.org/fair-principles/f4-metadata-registered-indexed-searchable-resource/)**

**<span style="text-decoration:underline;">A</span>ccessible**

Once the user finds the required data, she/he/they need to know how can they be accessed, possibly including authentication and authorisation.

**[A1. (Meta)data are retrievable by their identifier using a standardised communications protocol](https://www.go-fair.org/fair-principles/542-2/)**

**[A1.1 The protocol is open, free, and universally implementable](https://www.go-fair.org/fair-principles/a1-1-protocol-open-free-universally-implementable/)**

**[A1.2 The protocol allows for an authentication and authorisation procedure, where necessary](https://www.go-fair.org/fair-principles/a1-2-protocol-allows-authentication-authorisation-required/)**

**[A2. Metadata are accessible, even when the data are no longer available](https://www.go-fair.org/fair-principles/a2-metadata-accessible-even-data-no-longer-available/)**

**<span style="text-decoration:underline;">I</span>nteroperable**

The data usually need to be integrated with other data. In addition, the data need to interoperate with applications or workflows for analysis, storage, and processing.

**[I1. (Meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.](https://www.go-fair.org/fair-principles/i1-metadata-use-formal-accessible-shared-broadly-applicable-language-knowledge-representation/)**

**[I2. (Meta)data use vocabularies that follow FAIR principles](https://www.go-fair.org/fair-principles/i2-metadata-use-vocabularies-follow-fair-principles/)**

**[I3. (Meta)data include qualified references to other (meta)data](https://www.go-fair.org/fair-principles/i3-metadata-include-qualified-references-metadata/)**

**<span style="text-decoration:underline;">R</span>eusable**

The ultimate goal of FAIR is to optimise the reuse of data. To achieve this, metadata and data should be well-described so that they can be replicated and/or combined in different settings.

**[R1. (Meta)data are richly described with a plurality of accurate and relevant attributes](https://www.go-fair.org/fair-principles/r1-metadata-richly-described-plurality-accurate-relevant-attributes/)**

**[R1.1. (Meta)data are released with a clear and accessible data usage license](https://www.go-fair.org/fair-principles/r1-1-metadata-released-clear-accessible-data-usage-license/)**

**[R1.2. (Meta)data are associated with detailed provenance](https://www.go-fair.org/fair-principles/r1-2-metadata-associated-detailed-provenance/)**

**[R1.3. (Meta)data meet domain-relevant community standards](https://www.go-fair.org/fair-principles/r1-3-metadata-meet-domain-relevant-community-standards/)**

The principles refer to three types of entities: data (or any digital object), metadata (information about that digital object), and infrastructure. For instance, principle F4 defines that both metadata and data are registered or indexed in a searchable resource (the infrastructure component).


## The Dublin Core {#Dublin-Core}

|   |   |   
|:--|:-:|
| Contributor | An entity responsible for making contributions to the resource.|
|Coverage |The spatial or temporal topic of the resource, the spatial applicability of the resource, or the jurisdiction under which the resource is relevant. |
|Creator | An entity primarily responsible for making the resource.|
|Date | A point or period of time associated with an event in the lifecycle of the resource.|
|Description |An account of the resource.|
|Format |The file format, physical medium, or dimensions of the resource.|
|Identifier | An unambiguous reference to the resource within a given context.|
|Language | A language of the resource.|
|Publisher | An entity responsible for making the resource available. |
|Relation | A related resource. |
|Rights | Information about rights held in and over the resource.|
|Source | A related resource from which the described resource is derived.|
|Subject| The topic of the resource.|
|Title |A name given to the resource.|
|Type |The nature or genre of the resource.|

## DataCite  {#DataCite}

We use all [mandatory](https://support.datacite.org/docs/datacite-metadata-schema-v44-mandatory-properties) DataCite metadata fields, and many of [the recommended and optional](https://support.datacite.org/docs/datacite-metadata-schema-v44-recommended-and-optional-properties) ones. 

|   |   |   
|:--|:-:|
|Identifier | An unambiguous reference to the resource within a given context. (Dublin Core item), but several identifiders allowed, and we will use several of them.|
|Creator | The main researchers involved in producing the data, or the authors of the publication, in priority order. To supply multiple creators, repeat this property. (Extends the Dublin Core with multiple authors, and legal persons, and adds affiliation data.) |
|Title |A name given to the resource. Extends Dublin Core with alternative title
subtitle, translated Title, and other title(s) |
|Publisher | The name of the entity that holds, archives, publishes prints, distributes, releases, issues, or produces the resource. This property will be used to formulate the citation, so consider the prominence of the role. For software, use Publisher for the code repository. (Dublin Core item.) |
|Publication Year | The year when the data was or will be made publicly available. |
|Resource Type |We publish Datasets, Images, Report, and Data Papers. (Dublin Core item with controlled vocabulary.)|

### Recommended

|   |   |   
|:--|:-:|
|Subject| The topic of the resource. (Dublin Core item.)|
|Contributor | The institution or person responsible for collecting, managing, distributing, or otherwise contributing to the development of the resource. (Extends the Dublin Core with multiple authors, and legal persons, and adds affiliation data.) When applicable, we add Distributor (of the datasets and images), Contact Person, Data Collector, Data Curator, Data Manager, Hosting Institution, Producer (for images), Project Manager, Researcher, Research Group, Rightsholder, Sponsor, Supervisor |
|Date | A point or period of time associated with an event in the lifecycle of the resource, besides the Dublin Core minimum we add Collected, Created, Issued, Updated, and if necessary, Withdrawn dates to our datasets.|
|Language | A language of the resource. (Dublin Core item.)|
|Alternative Identifier |An identifier or identifiers other than the primary Identifier applied to the resource being registered. |
|Related Identifier |An identifier or identifiers other than the primary Identifier applied to the resource being registered. |
|Size |We give the CSV, downloadable dataset size in bytes. |
|Format |We give file format information. We mainly use CSV and JSON, and occasionally rds and SPSS types. (Dublin Core item.) |
|Version | The version number of the resource.  |
|Rights | We give standards rights description with URLs to the actual license. (Dublin Core item.)|
|Description | Recommended for discovery.(Dublin Core item.) |
|GeoLocation | Similar to Dublin Core item Coverage |
|Funding Reference |We provide the funding reference information when applicable. This is usually mandatory with public funds. |
|Related Item |We give information about our observatory partners' related research products, awards, grants (also Dublin Core item as Relation.) We particularly include source information when the dataset is derived from another resource (which is a Dublin Core item.)|

## Processing Metadata

|   |   |   
|:--|:-:|
|Value Type| We observe actual, missing, imputed, estimated values. |
|Method| If the value is estimated, we provide modelling information.|
|Unit| We provide the measurement unit of the data (when applicable.)|
|Frequency| We provide the measurement frequency of the data in a more practical format than the Dublin Core and DataCite descriptive dates. |
|Related Item |We give information about the software code that processed the data (both Dublin Core and DataCite compliant.)|

## Tidy Data {#tidy-data}

A dataset is a collection of values, usually either numbers (if quantitative) or strings (if qualitative). Values are organised in two ways. Every value belongs to a variable and an observation. A variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units. An observation contains all values measured on the same unit (like a person, or a day, or a race) across attributes.

It is often said that 80% of data analysis is spent on the cleaning and preparing data. And it’s not just a first step, but it must be repeated many times over the course of analysis as new problems come to light or new data is collected. The tidy data principle applies a certain structure to datasets that facilitates immediate use and reuse. 

The principles of tidy data provide a standard way to organise data values within a dataset. A standard makes initial data cleaning easier because you don’t need to start from scratch and reinvent the wheel every time. 

Tidy data is a standard way of mapping the meaning of a dataset to its structure (. A dataset is messy or tidy depending on how rows, columns and tables are matched up with observations, variables and types. 

In tidy data we need a way to describe the underlying semantics, or meaning, of the values displayed in the table:

- Every column is a variable.
- Every row is an observation.
- Every cell is a single value.

## Messy data

Real datasets can, and often do, violate the three precepts of tidy data in almost every way imaginable -- this particulary true of open data, even when it is released by statistical bodies. The most typical errors:

* Column headers are values, not variable names.
* Multiple variables are stored in one column, for example, the number of item purchased and the price of the item.
* Variables are stored in both rows and columns, for example, the columns are organized by income level groups. 
* Multiple types of observational units are stored in the same table. For example, names of musicians and their songs.
* A single observational unit is stored in multiple tables.

While messy data almost always can be tidied, if you do this in a spreadsheet application manually, it is almost impossible not to make a mistake.  Spreadsheet applications do not check the tidyness of the data, and do not record the logs of your manual tidying efforts.  Unless every single mouseclick, drag and drop is recorded, the work is impossible to validate. However, we believe that data should never be manipulated with a mouse.  Computer algorithms should be deployed in a way that our their tidying efforts are reproducible and logged.